{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa0a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for api request\n",
    "import requests as re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd97711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language detection\n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78db85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#package for sentiment analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a84049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reddit_data(sia, start, end, coin, restrict_score = '>0', size = 50, fields = [\n",
    "    'num_comments', 'title', 'score', 'upvote_ratio', 'subreddit']):\n",
    "    \"\"\"\n",
    "    Given sentiment analyzer, a date range and coin:\n",
    "    1) Get size reddit posts about that coin sorted from highest to lowest score.\n",
    "    2) Remove duplicated posts.\n",
    "    3) Remove non-english posts.\n",
    "    4) Get sentiment scores.\n",
    "        restrict_score must be in the format >int or <int\n",
    "        max value for size is 500\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1925f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_api_request(start, end, coin, restrict_score, size, fields):\n",
    "        base_url = 'https://api.pushshift.io/reddit/search/submission/'\n",
    "        params = {\n",
    "            'title': coin,\n",
    "            'fields': fields,\n",
    "            'sort_type': 'score',\n",
    "            'score': restrict_score,\n",
    "            'after':  create_epoch(start, '00:00:01'),\n",
    "            'before': create_epoch(end, '23:59:59'),\n",
    "            'size': size\n",
    "        }\n",
    "        return re.get(base_url, params).json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8c5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epoch(date, clock):\n",
    "        \"\"\"Given date (format = ‘mm/dd/yyyy’) and clock (format = 'HH:MM:SS') return the Epoch.\"\"\"\n",
    "        date_time = f\"{date} {clock}\"\n",
    "        pattern = '%m/%d/%Y %H:%M:%S'\n",
    "        return int(time.mktime(time.strptime(date_time, pattern)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf030f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_titles(posts):\n",
    "        \"\"\"Removes posts based on duplicate titles.\n",
    "        Caveot: posts with identical titles from different authors will be lost.\n",
    "        However, this should only affect a small proportion of the data and will \n",
    "        catch posts resubmitted by bot accounts.s\"\"\"\n",
    "        def titler(post):\n",
    "             titles.append(post['title'])\n",
    "             return post\n",
    "\n",
    "        titles = []\n",
    "        return [titler(post) for post in posts if post['title'] not in titles]\n",
    "    \n",
    "def get_english_posts(posts):\n",
    "        english_posts = []\n",
    "\n",
    "        for post in posts:\n",
    "            if langid.classify(post['title'])[0] == 'en':\n",
    "                english_posts.append(post)\n",
    "        return english_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac6bc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(posts, sia):\n",
    "        for post in posts:\n",
    "            post['sentiment_scores'] = sia.polarity_scores(post['title'])\n",
    "        return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef5c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
